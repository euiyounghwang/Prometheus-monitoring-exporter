{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1301,
   "id": "a176f610-cf34-41d3-902d-cac996cb5878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the records if index has duplicate recores\n"
     ]
    }
   ],
   "source": [
    "''' Jupyter Notebook is an incredibly powerful tool for interactively developing and presenting data science projects.  '''\n",
    "''' It allows you to run code, display the results, and add explanations, formulas, and charts all in one place.  '''\n",
    "\n",
    "''' Script that can check for duplicate entries for TASK documents, it would be great if we could do this for all WMx/OMx ES indices.'''\n",
    "''' Modify your script to check for any process name by the below field(s) to see if any duplicate data exists. '''\n",
    "print(f\"Check the records if index has duplicate recores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "id": "bfa7a8d7-7409-4020-a4e2-ec8b907c6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y elasticsearch\n",
    "#!pip install elasticsearch==7.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "id": "6a58b73c-bd80-4906-b7df-57e3c87c6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "id": "01c8a2d0-6fea-47f6-aa47-7272e41717ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: elasticsearch\n",
      "Version: 7.13.0\n",
      "Summary: Python client for Elasticsearch\n",
      "Home-page: https://github.com/elastic/elasticsearch-py\n",
      "Author: Honza Kr√°l, Nick Lang\n",
      "Author-email: honza.kral@gmail.com, nick@nicklang.com\n",
      "License: Apache-2.0\n",
      "Location: /home/biadmin/monitoring/jupyter_notebook/.venv/lib/python3.9/site-packages\n",
      "Requires: certifi, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "id": "8f63ef6e-8aec-4897-a230-d2ff40ea3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "id": "df8cea7f-c5ae-4cab-ae5d-9d7a272a35e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' pip install python-dotenv'''\n",
    "load_dotenv() # will search for .env file in local folder and load variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "id": "3fcd93bf-191a-4bff-876f-010802bf629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers():\n",
    "    ''' Elasticsearch Header '''\n",
    "    return {\n",
    "            'Content-type': 'application/json', \n",
    "            'Authorization' : '{}'.format(os.getenv('BASIC_AUTH')),\n",
    "            'Connection': 'close'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "2d9a80da-4712-41ef-b5db-a1aea3e96f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_es_instance(host):\n",
    "    es_client = Elasticsearch(hosts=\"http://{}\".format(host), headers=get_headers(), timeout=5,  verify_certs=False)\n",
    "    return es_client\n",
    "\n",
    "# es_obj_s_client = get_es_instance(\"localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "id": "a0238edd-55c4-4f4d-8ac6-43233b143bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = es_obj_s_client.cluster.health()\n",
    "# print(json.dumps(resp, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "id": "62db2a74-e4c0-4f5b-8a79-e44cea9f050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_host_duplicates = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "id": "a986a0be-0f8c-446e-8b07-f0c43871a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_value_to_transform_trim(raw_json):\n",
    "    ''' update value in the form of json format'''\n",
    "    # print(f\"raw_json : {raw_json}\")\n",
    "    def get_recursive_nested_all(d):\n",
    "        # print(f\"get_recursive_nested_all : {d}\")\n",
    "        if isinstance(d, list):\n",
    "            for i in d:\n",
    "                get_recursive_nested_all(i)\n",
    "        elif isinstance(d, dict):\n",
    "            for k, v in d.items():\n",
    "                if not isinstance(v, (list, dict)):\n",
    "                    # print(\"%%%%\", k, v)\n",
    "                    d[k] = v\n",
    "                else:\n",
    "                    # print(\"####\", k, v)\n",
    "                    get_recursive_nested_all(v)\n",
    "        return d\n",
    "\n",
    "    return get_recursive_nested_all(raw_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "id": "3464c3fc-69d0-43c3-9f54-ab0e77e238ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_handler(process):\n",
    "    ''' check dsl for any duplicates '''\n",
    "    '''https://stackoverflow.com/questions/53076349/script-writing-to-get-distinct-value-from-elasticsearch '''\n",
    "    ''' https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-script '''\n",
    "    ''' So you can see in the results as how key are constructed (keys are unique). '''\n",
    "    if process == 'sample':\n",
    "        query = {\n",
    "          \"size\": 0,\n",
    "          \"aggs\": {\n",
    "            \"duplicates\": {\n",
    "              \"terms\": {\n",
    "                    \"field\": \"TASKID\",\n",
    "                    \"min_doc_count\": 2,\n",
    "                    \"size\" : 10000  \n",
    "                }\n",
    "             }\n",
    "          }\n",
    "        }\n",
    "    elif process == 'wx_task':\n",
    "        query = {\n",
    "          \"size\": 0,\n",
    "          \"aggs\": {\n",
    "            \"duplicates\": {\n",
    "              \"terms\": {\n",
    "                \"script\": {\n",
    "                  \"source\": \"doc['TASKID'].value\",\n",
    "                  \"lang\": \"painless\",\n",
    "                  \"params\": {\n",
    "                    \"param\": \",\"\n",
    "                  }\n",
    "                },\n",
    "                \"min_doc_count\": 2,\n",
    "                \"size\" : 10000\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    elif process == 'wx_asn':\n",
    "         query = {\n",
    "          \"size\": 0,\n",
    "          \"aggs\": {\n",
    "            \"duplicates\": {\n",
    "              \"terms\": {\n",
    "                \"script\": {\n",
    "                  \"source\": \"doc['ASNKEY.keyword'].value + params.param + doc['SITEID.keyword'].value\",\n",
    "                  \"lang\": \"painless\",\n",
    "                  \"params\": {\n",
    "                    \"param\": \",\"\n",
    "                  }\n",
    "                },\n",
    "                \"min_doc_count\": 2,\n",
    "                \"size\" : 10000\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    elif process == 'wx_orderdtl':\n",
    "        query = {\n",
    "          \"size\": 0,\n",
    "          \"aggs\": {\n",
    "            \"duplicates\": {\n",
    "              \"terms\": {\n",
    "                \"script\": {\n",
    "                  \"source\": \"doc['ORDERKEY.keyword'].value + params.param + doc['ORDERLINENO'].value + params.param + doc['SITEID.keyword'].value\",\n",
    "                  \"lang\": \"painless\",\n",
    "                  \"params\": {\n",
    "                    \"param\": \",\"\n",
    "                  }\n",
    "                },\n",
    "                \"min_doc_count\": 2,\n",
    "                \"size\" : 10000\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    elif process == 'wx_inv_hold':\n",
    "        query = {\n",
    "          \"size\": 0,\n",
    "          \"aggs\": {\n",
    "            \"duplicates\": {\n",
    "              \"terms\": {\n",
    "                \"script\": {\n",
    "                  \"source\": \"doc['INVHOLDID'].value\",\n",
    "                  \"lang\": \"painless\",\n",
    "                  \"params\": {\n",
    "                    \"param\": \",\"\n",
    "                  }\n",
    "                },\n",
    "                \"min_doc_count\": 2,\n",
    "                \"size\" : 10000\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    elif process == 'wx_inv_holdtrans':\n",
    "        query = {\n",
    "          \"size\": 0,\n",
    "          \"aggs\": {\n",
    "            \"duplicates\": {\n",
    "              \"terms\": {\n",
    "                \"script\": {\n",
    "                  \"source\": \"doc['INVHOLDTRANSID'].value\",\n",
    "                  \"lang\": \"painless\",\n",
    "                  \"params\": {\n",
    "                    \"param\": \",\"\n",
    "                  }\n",
    "                },\n",
    "                \"min_doc_count\": 2,\n",
    "                \"size\" : 10000\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    elif process == 'om_appointment':\n",
    "        query = {\n",
    "          \"size\": 0,\n",
    "          \"aggs\": {\n",
    "            \"duplicates\": {\n",
    "              \"terms\": {\n",
    "                \"script\": {\n",
    "                  \"source\": \"doc['CRN'].value\",\n",
    "                  \"lang\": \"painless\",\n",
    "                  \"params\": {\n",
    "                    \"param\": \",\"\n",
    "                  }\n",
    "                },\n",
    "                \"min_doc_count\": 2,\n",
    "                \"size\" : 10000\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    return process, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "id": "80a63282-6377-4ab8-8a68-4bc89251e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates_tasks(env, process):\n",
    "    ''' check duplicates'''\n",
    "    \n",
    "    # print('\\n', env)\n",
    "    # print(os.getenv(\"{}_ES_HOST\".format(str(env).upper())))\n",
    "    es_host = \"{}_ES_HOST\".format(str(env).upper())\n",
    "    dataframe_column.append(es_host)\n",
    "    dataframe_process.append(process)\n",
    "\n",
    "    if 'wx' in process:\n",
    "        dataframe_db.append('WMx DB')\n",
    "    elif 'om' in process:\n",
    "        dataframe_db.append('OMx DB')\n",
    "    # print(es_host)\n",
    "    \n",
    "    ''' instance '''\n",
    "    es_obj_s_client = get_es_instance(os.getenv(es_host))\n",
    "    dataframe_es_client.append(es_obj_s_client)\n",
    "\n",
    "    ''' return index_name and query '''\n",
    "    index_name, query = query_handler(process)\n",
    "    \n",
    "    response = es_obj_s_client.search(index=index_name, body=query)\n",
    "    # print(json.dumps(response, indent=2))\n",
    "    \n",
    "    duplicates_list = response['aggregations']['duplicates']['buckets']\n",
    "    \n",
    "    # print(f\"total duplicates : {json.dumps(len(duplicates_list), indent=2)}\")\n",
    "    # print(json.dumps(duplicates_list, indent=2))\n",
    "    # lookup = json_value_to_transform_trim(response['aggregations'])\n",
    "    # print(f\"lookup - type(lookup) : {type(lookup)}, lookup : {lookup}\")\n",
    "\n",
    "    es_host_duplicates.update({es_host : len(duplicates_list)})\n",
    "    dataframe_value.append(len(duplicates_list))\n",
    "\n",
    "    # return dataframe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "id": "3e55348d-2e06-4854-bb2f-24a8fa550f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressing for prod1 ..\n",
      "Progressing for prod2 ..\n"
     ]
    }
   ],
   "source": [
    "# env_list = ['prod1','prod2','prod3','prod4','prod6','prod7','prod8','prod9','prod10','prod12','prod13','prod14','prod16','prod17','prod18','prod19','prod20']\n",
    "env_list = ['prod1','prod2']\n",
    "dataframe_dict = {}\n",
    "dataframe_column, dataframe_process, dataframe_es_client, dataframe_value, dataframe_db = [], [], [], [], []\n",
    "\n",
    "''' Script that can check for duplicate entries for TASK documents, it would be great if we could do this for all WMx/OMx ES indices.'''\n",
    "''' Modify your script to check for any process name by the below field(s) to see if any duplicate data exists. '''\n",
    "# process_name = ['wx_task', 'wx_inv_hold', 'wx_inv_holdtrans', 'om_appointment', 'wx_asn']\n",
    "process_name = ['wx_task', 'wx_asn', 'wx_orderdtl']\n",
    "for env in env_list:\n",
    "    print(f\"Progressing for {env} ..\")\n",
    "    for each_index in process_name:\n",
    "        check_duplicates_tasks(env, each_index)\n",
    "# print('\\n Duplicate records')\n",
    "# print(json.dumps(dataframe_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "id": "5a7025bb-715c-4331-a009-1fa959af351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' update dict for dataframe '''\n",
    "dataframe_dict.update({'ES_Cluster' : dataframe_column})\n",
    "dataframe_dict.update({'ES URL' : dataframe_es_client})\n",
    "dataframe_dict.update({'DB' : dataframe_db})\n",
    "dataframe_dict.update({'Process_Name' : dataframe_process})\n",
    "dataframe_dict.update({'Duplicates_Count' : dataframe_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "id": "ba7c9f54-688c-4681-9770-d3c17ab2e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataframe_dict)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "id": "3c0aea2a-277e-4a15-9ee4-bb504ca90f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to Excel\n",
    "# df.to_csv(\"duplicate.csv\")\n",
    "# print(\"Export csv files successfully..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "id": "0d51f27c-3714-4443-a0b4-409fb7462de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' filter if any duplicate data exist in df dataframe '"
      ]
     },
     "execution_count": 1318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' filter if any duplicate data exist in df dataframe '''\n",
    "# display(df.filter(items=['ES_Cluster', 'Process_Name'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "id": "d78b6b06-5616-4f15-9f12-299116907564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES_Cluster</th>\n",
       "      <th>ES URL</th>\n",
       "      <th>DB</th>\n",
       "      <th>Process_Name</th>\n",
       "      <th>Duplicates_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ES_Cluster, ES URL, DB, Process_Name, Duplicates_Count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' check if any duplicate data exist in df dataframe '''\n",
    "df = df[df['Duplicates_Count'] > 0]\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
