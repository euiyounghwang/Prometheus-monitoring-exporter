input
{
	# https://github.com/vklochan/python-logstash/tree/master
    beats {
       port => 5044
    }

    tcp
	{
	    type => "TCP_LOG"
		port => 5950
		codec => json
		#codec => plain
	}

    udp
	{
	    type => "UDP_LOG"
		port => 5959
		codec => json
	}

	# 24/10/28 16:46:50 INFO myLogger: 2024-10-28 16:46:50.886 DB Execute for TEST on key1 87519828, K
	# 24/10/28 16:46:50 INFO PluginsService: loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin
	# - Error
	# [StreamProcessExecutor.log] [Dev] 24/10/11 12:35:38 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 107,5,main]
	# java.lang.OutOfMemoryError: Java heap space
    #     at java.util.Arrays.copyOf(Arrays.java:3332)
	# - Error
	# {'message': '[StreamProcessExecutor.log] [Dev] org.apache.kafka.common.errors.DisconnectException: null\n'
}

filter
{
   #ruby {
   #     code => "event.set('timestamp', event.get('@timestamp').time.localtime('-04:00').strftime('%Y-%m-%d %H:%M:%S'))"
   #}
    

   if [message] =~ "myLogger"
   {
		grok {
				match => 
					{ 
						"message" => 
						[
							# python-logger
							#"\[%{GREEDYDATA:log_filename}\] \[%{GREEDYDATA:env}\] %{WORD:RM1}\/%{WORD:RM2}\/%{WORD:RM3} %{WORD:RM4}\:%{WORD:RM5}:%{WORD:RM6} %{WORD:log_level} %{WORD:log_name}\: %{TIMESTAMP_ISO8601:logger_date} %{GREEDYDATA:log_message}"
							# filebeat
							"%{WORD:RM1}\/%{WORD:RM2}\/%{WORD:RM3} %{WORD:RM4}\:%{WORD:RM5}:%{WORD:RM6} %{WORD:log_level} %{WORD:log_name}\: %{TIMESTAMP_ISO8601:timestamp} %{GREEDYDATA:log_message}"
						]
					}
			}
	}
	else if [message] =~ "ERROR"
	{
		grok {
				match => 
					{ 
						"message" => 
						[
							# filebeat
							# 24/11/07 17:24:46 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM",
							"%{WORD:RM1}\/%{WORD:RM2}\/%{WORD:RM3} %{WORD:RM4}\:%{WORD:RM5}:%{WORD:RM6} %{WORD:log_level} %{GREEDYDATA:log_message}"
						]
					}
			}
		add_field => { "timestamp" => "%{+YYYY}-%{RM2}-%{RM3} %{RM4}:%{RM5}:%{RM6}" }
	}
	else {
		drop {}
	}

	mutate
	{
	#    rename => { "type" => "TYPE"}
	#    rename => { "host" => "HOST"}
	#   rename => { "message" => "raw_data"}
	#    add_field => { "INPUTDATE" => "%{TIMESTAMP}" }
	#    add_field => { "event" => {"original" : {"%{LOG_LEVEl}"}}}
	#   add_field => { "LOGGER_DATE" => "%{RM1}%{RM2}%{RM3}" }
	   remove_field => ["message", "RM1", "RM2", "RM3", "RM4", "RM5", "RM6", "taskName", "level", "port", "tags", "type", "@version", "log_name", "logger_name", "offset", "input_type", "[beat][hostname]", "[beat][name]"]


	   gsub => [
		"log_message", "\\n'}", ""
	   ]
	}
}

output
{
   elasticsearch
   {
        hosts => "localhost:9200"
        #user => "elastic"
        #    # password => "${LOGSTASH_INTERNAL_PASSWORD}"
        index => "logstash-logger-%{+YYYY.MM.dd}"
   }
	
   stdout
   {
		codec => rubydebug
   }
}